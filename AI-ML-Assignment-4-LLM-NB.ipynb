{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a04e2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\awubs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#Lets write a story \n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "torch_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# add the EOS token as PAD token to avoid warnings\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id).to(torch_device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6966f76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode context the generation is conditioned on\n",
    "model_inputs = tokenizer('A long time ago in a galaxy far, far away...', return_tensors='pt').to(torch_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60f78943",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "A long time ago in a galaxy far, far away...\n",
      "\n",
      "It's a messed-up mess. Type = ST-34: Second Man\n",
      "\n",
      "It's a long time ago in a galaxy far, far away...\n",
      "\n",
      "Finally, Subvariant Robo recovered his radio service.\n",
      "\n",
      "What is this? A new form of technology, it's a barely disguised attack by someone who's worked so hard to make the planet habitable. Some people think it weapons or an infection weapon, call it now a new military Command Center. Press the \"\n"
     ]
    }
   ],
   "source": [
    "# Core Implementation \n",
    "sample_output = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=100,\n",
    "    do_sample=True,\n",
    "    top_k=0\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(sample_output[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50915e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "A long time ago in a galaxy far, far away...\n",
      "\n",
      "Some thought he was going there because now he had finally found the right place...\n",
      "\n",
      "'What do you mean I don't like? I REALLY do...' That word was met with a huff of laughter from the very end.\n",
      "\n",
      "Mark had quickly picked up on that sentiment once again.\n",
      "\n",
      "'It's not something I can just do. I've had the feeling my sister would want to have me along for the ride right now and I would've still had enough\n"
     ]
    }
   ],
   "source": [
    "# Modifying Temperature\n",
    "sample_output = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=100,\n",
    "    do_sample=True,\n",
    "    temperature=0.8, \n",
    "    top_k=0\n",
    "\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(sample_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b538e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "A long time ago in a galaxy far, far away... the Dropship's guardian angel was about to encounter a corrupted soul with some creation setting the course of his journey. Through a wormhole dedicated to destroying the Chosen for good, she trapped him. But before she could face that challenge... he was sucked into the place, sealed into the slumberlight, as if it were a place far deeper than can be seen or experienced.\n",
      "\n",
      "Well, six of her biggest puzzles ever, with the most biggest problems always happening in quick succession. A Sparkling Fruit which she had captured in search of the Lich known as Markus â€” the powerful Lich friend of the fallen nomads and world-renowned leech. His mysterious cloak grew in its cards and Dazzle beat me with it swinging my\n"
     ]
    }
   ],
   "source": [
    "# Modifying Max New Tokens\n",
    "sample_output = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=150,\n",
    "    do_sample=True,\n",
    "    top_k=0\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(sample_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc6d6470",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "A long time ago in a galaxy far, far away... a shambling mecha robot heart-leveled teacher from a hefty order in a lab (wannabe, sadist, robotics engineer, the kind of person who will change his course through meaningless repetition) took our job. With extreme imprimatur, he wanted to take our shoes, replace our nikes, and toy with the latest Barbie, Moby Dick, the fresh power of skateboarding, and leave us with several extra hours of adulthood and more. Whether he could tell us is\n"
     ]
    }
   ],
   "source": [
    "#Modifying Top-P \n",
    "sample_output = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=100,\n",
    "    do_sample=True,\n",
    "    top_p=0.92, \n",
    "    top_k=0\n",
    "\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(sample_output[0], skip_special_tokens=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
